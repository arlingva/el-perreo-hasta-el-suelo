library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(stopwords)
language <- "es"
stopwords <- stopwords("es")
stopwords <- c(stopwords, chartr("áéíóú", "aeiou", stopwords)) %>%
unique()
length(stopwords)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
proyecto_canciones <- read_excel("data/proyecto canciones.xlsx") %>%
clean_names()
n <- proyecto_canciones$id %>%
length()
proyecto_canciones %>%
head()
clean.letra <- proyecto_canciones$letra %>%
clean_tweet()
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet)
num.palabras.v1 <- c()
for(i in 1:n){
clean.letra.v1[[i]] %>%
unique() %>%
length() -> num.palabras.v1[i]
}
clean.letra.df <- unlist(clean.letra.v1) %>%
as.data.frame()
colnames(clean.letra.df) <- "word"
clean.letra.df <- clean.letra.df %>%
group_by(word) %>%
summarise(freq = n()) %>%
arrange(desc(freq)) %>%
filter(!is.na(word))
set.seed(1234) # for reproducibility
wordcloud(words = clean.letra.df$word, freq = clean.letra.df$freq,
min.freq = 1, max.words=200, random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE, exlude_stopwords = TRUE)
tokenize_tweet
library(stopwords)
stopwords <- C(stopwords("es"), stopwords("eN"))
library(stopwords)
stopwords <- C(stopwords("es"), stopwords("en"))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(stopwords)
stopwords <- c(stopwords("es"), stopwords("en"))
stopwords <- c(stopwords, chartr("áéíóú", "aeiou", stopwords)) %>%
unique()
length(stopwords)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
procesamiento <- function(df, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2){
## Antes de eliminar stopwords
clean.letra <- df$letra %>%
clean_tweet()
## Número de palabras únicas previo a eliminar stopwords.
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
## Limpieza de datos
### Limpieza de datos sin stemming, excluyendo stopwords.
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
## Número de palabras únicas después de eliminar stopwords.
num.palabras.v1 <- c()
for(i in 1:n){
clean.letra.v1[[i]] %>%
unique() %>%
length() -> num.palabras.v1[i]
}
## Lista de palabras
clean.letra.df <- unlist(clean.letra.v1) %>%
as.data.frame()
colnames(clean.letra.df) <- "word"
clean.letra.df <- clean.letra.df %>%
group_by(word) %>%
summarise(freq = n()) %>%
arrange(desc(freq)) %>%
filter(!is.na(word))
df <- cbind(df, num.palabras.rep, clean.letra.v1)
return(list(df, clean.letra.df))
}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
procesamiento <- function(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
procesamiento <- function(df, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2){
## Antes de eliminar stopwords
clean.letra <- df$letra %>%
clean_tweet()
## Número de palabras únicas previo a eliminar stopwords.
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
## Limpieza de datos
### Limpieza de datos sin stemming, excluyendo stopwords.
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
## Número de palabras únicas después de eliminar stopwords.
num.palabras.v1 <- c()
for(i in 1:n){
clean.letra.v1[[i]] %>%
unique() %>%
length() -> num.palabras.v1[i]
}
## Lista de palabras
clean.letra.df <- unlist(clean.letra.v1) %>%
as.data.frame()
colnames(clean.letra.df) <- "word"
clean.letra.df <- clean.letra.df %>%
group_by(word) %>%
summarise(freq = n()) %>%
arrange(desc(freq)) %>%
filter(!is.na(word))
df <- cbind(df, num.palabras.rep, clean.letra.v1)
return(list(df, clean.letra.df))
}
prueba <- procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
prueba
prueba$df
prueba[[1]]
procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
prueba <- procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
View(prueba)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(stopwords)
stopwords <- c(stopwords("es"), stopwords("en"))
stopwords <- c(stopwords, chartr("áéíóú", "aeiou", stopwords)) %>%
unique()
length(stopwords)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
proyecto_canciones <- read_excel("data/proyecto canciones.xlsx") %>%
clean_names()
n <- proyecto_canciones$id %>%
length()
proyecto_canciones %>%
head()
proyecto_canciones
prueba <- procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
df <- proyecto_canciones
clean.letra <- df$letra %>%
clean_tweet()
clean.letra
## Número de palabras únicas previo a eliminar stopwords.
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
proyecto_canciones
## Número de palabras únicas previo a eliminar stopwords.
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
num.palabras.rep
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
clean.letra.v1
num.palabras.v1 <- c()
for(i in 1:n){
clean.letra.v1[[i]] %>%
unique() %>%
length() -> num.palabras.v1[i]
}
num.palabras.v1
## Lista de palabras
clean.letra.df <- unlist(clean.letra.v1) %>%
as.data.frame()
colnames(clean.letra.df) <- "word"
clean.letra.df <- clean.letra.df %>%
group_by(word) %>%
summarise(freq = n()) %>%
arrange(desc(freq)) %>%
filter(!is.na(word))
data.frame[df, num.palabras.rep, clean.letra.v1]
df
cbind(df, num.palabras.rep)
clean.letra.v1
cbind(df, num.palabras.rep, num.palabras.v1)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(stopwords)
stopwords <- c(stopwords("es"), stopwords("en"))
stopwords <- c(stopwords, chartr("áéíóú", "aeiou", stopwords)) %>%
unique()
length(stopwords)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
proyecto_canciones <- read_excel("data/proyecto canciones.xlsx") %>%
clean_names()
n <- proyecto_canciones$id %>%
length()
proyecto_canciones %>%
head()
prueba <- procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
prueba
prueba$df
prueba[[1]]
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
proyecto_canciones <- read_excel("data/proyecto canciones.xlsx") %>%
clean_names()
n <- proyecto_canciones$id %>%
length()
proyecto_canciones %>%
head()
prueba <- procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
prueba
procesamiento(proyecto_canciones, stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
df <- proyecto_canciones
clean.letra <- df$letra %>%
clean_tweet()
## Número de palabras únicas previo a eliminar stopwords.
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
n <- df$id %>%
length()
clean.letra.v1 <- list()
clean.letra.v1
for(i in 1:n){
clean.letra.v1[[i]] <- tokenize_tweet(clean.letra[i])
}
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 2)
clean.letra[1]
tokenize_tweet(clean.letra[1])
function(tweet, stemming = FALSE,
exclude_stopwords = TRUE,
nmin = 1){
tweet <- str_split(tweet, " ")[[1]]
if(stemming == TRUE){tweet <- text_tokens(tweet, stemmer = "es")}
if(exclude_stopwords == TRUE){tweet <- tweet[tweet %notin% stopwords]}
tweet <- tweet[tweet != ""]
tweet <- tweet[str_length(tweet) > nmin]
tweet <- unlist(tweet)
return(tweet)
}
tokenize_tweet(clean.letra[1])
#for(i in 1:n){clean.letra.v1[[i]] <- tokenize_tweet(clean.letra[1])}
clean.letra.v1 <- lapply(clean.letra)
#for(i in 1:n){clean.letra.v1[[i]] <- tokenize_tweet(clean.letra[1])}
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(dplyr)
library(magrittr)
library(readr)
library(readxl)
library(tidyr)
library(stringr)
library(janitor)
rm(list = ls())
`%notin%` = function(x,y) !(x %in% y)
source("funciones.R")
library(stopwords)
stopwords <- c(stopwords("es"), stopwords("en"))
stopwords <- c(stopwords, chartr("áéíóú", "aeiou", stopwords)) %>%
unique()
length(stopwords)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
proyecto_canciones <- read_excel("data/proyecto canciones.xlsx") %>%
clean_names()
n <- proyecto_canciones$id %>%
length()
proyecto_canciones %>%
head()
clean.letra <- proyecto_canciones$letra %>%
clean_tweet()
num.palabras.rep <- c()
for(i in 1:n){
str_split(clean.letra, " ")[[i]] %>%
unique() %>%
length() -> num.palabras.rep[i]
}
clean.letra.v1 <- lapply(clean.letra, tokenize_tweet,
stemming = FALSE,
exclude_stopwords = TRUE, nmin = 1)
num.palabras.v1 <- c()
for(i in 1:n){
clean.letra.v1[[i]] %>%
unique() %>%
length() -> num.palabras.v1[i]
}
clean.letra.df <- unlist(clean.letra.v1) %>%
as.data.frame()
colnames(clean.letra.df) <- "word"
clean.letra.df <- clean.letra.df %>%
group_by(word) %>%
summarise(freq = n()) %>%
arrange(desc(freq)) %>%
filter(!is.na(word))
clean.letra.df
knitr::opts_chunk$set(echo = FALSE, message = FALSE,
warning = FALSE)
library(readxl)
library(janitor)
library(dplyr)
library(tidyr)
rm(list=ls())
filename_vec <- c("data/Base Italian-V05.xlsx",
"data/Base Cielito Querido-V03.xlsx",
"data/Base Punta del Cielo-V03.xlsx",
"data/Base Otras marcas-V06.xlsx",
"data/Base Tim Hortons-V05.xlsx",
"data/Base Mexicali-V03.xlsx")
knitr::opts_chunk$set(echo = TRUE)
#rm(list=ls())
library(bigrquery)
library(magrittr)
library(dplyr)
library(readxl)
library(geosphere)
library(plotly)
library(tidyr)
library(lubridate)
library(sf)
graficaPuntos <- function(df, isDensity, vcenter, vzoom){
fig <- df %>%
plot_ly(
type = if_else(isDensity, 'densitymapbox','scattermapbox'),
lat = ~lat,
lon = ~lon,
#marker = list(color = "red"),
radius = 4)
fig <- fig %>%
layout(
mapbox = list(
style="stamen-terrain",
zoom =vzoom,
center = list(lon = vcenter[1], lat = vcenter[2])))
fig
}
Time <- function(vector){
TimeUTC<-as.POSIXct(vector,'UTC')
TimeMST<-with_tz(TimeUTC, 'MST')
return(TimeMST)
}
projectid <- "movilidadcovid"
bq_auth(path = "../movilidadcovid-2e817ce999b9.json")
options(digit = 10)
sql.1 <- "SELECT
id_adv,
timestamp,
lat,
lon,
tier1,
tier2
FROM `movilidadcovid.Movilidad.Hermosillo`
WHERE DATE(timestamp)
BETWEEN \"2020-10-01\"
AND \"2020-10-31\"
ORDER BY
id_adv,
timestamp"
dfX <- bq_project_query(projectid, query = sql.1) %>%
bq_table_download()
knitr::opts_chunk$set(echo = TRUE)
#rm(list=ls())
library(bigrquery)
library(magrittr)
library(dplyr)
library(readxl)
library(geosphere)
library(plotly)
library(tidyr)
library(lubridate)
library(sf)
graficaPuntos <- function(df, isDensity, vcenter, vzoom){
fig <- df %>%
plot_ly(
type = if_else(isDensity, 'densitymapbox','scattermapbox'),
lat = ~lat,
lon = ~lon,
#marker = list(color = "red"),
radius = 4)
fig <- fig %>%
layout(
mapbox = list(
style="stamen-terrain",
zoom =vzoom,
center = list(lon = vcenter[1], lat = vcenter[2])))
fig
}
Time <- function(vector){
TimeUTC<-as.POSIXct(vector,'UTC')
TimeMST<-with_tz(TimeUTC, 'MST')
return(TimeMST)
}
projectid <- "movilidadcovid"
bq_auth(path = "../movilidadcovid-2e817ce999b9.json")
df2$tier1 %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq)) %>%
head()
df2 <- df.1
#df.1 <- read.csv("output/df.1.csv")
df.1 <- read.csv("../output/octubre.csv")
